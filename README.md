# ğŸš— EstimaciÃ³n de Precios de VehÃ­culos
Este proyecto tiene como objetivo procesar las caracterÃ­sticas de distintos vehÃ­culos para realizar anÃ¡lisis y estimar sus precios basados en la informaciÃ³n de una base de datos proporcionada por una pÃ¡gina web de venta de vehÃ­culos.

A travÃ©s de este proyecto, se entrenan y comparan los resultados de cuatro modelos de Machine Learning para determinar cuÃ¡l de ellos ofrece la mejor estimaciÃ³n de los precios.
## ğŸ“Œ DescripciÃ³n
El conjunto de datos utilizado incluye diversas caracterÃ­sticas de vehÃ­culos, como:

- âœ… Marca
- âœ… Modelo
- âœ… AÃ±o
- âœ… Kilometraje
- âœ… Tipo de combustible
- âœ… Color
- âœ… Y mÃ¡sâ€¦

A partir de estos datos, se busca predecir el precio de los vehÃ­culos en base a sus caracterÃ­sticas.

Los modelos entrenados y evaluados son:

- ğŸ”¹ RegresiÃ³n Lineal
- ğŸ”¹ Ãrbol de DecisiÃ³n
- ğŸ”¹ Bosque Aleatorio
- ğŸ”¹ LightGBM

Cada modelo es evaluado utilizando la mÃ©trica RECM (RaÃ­z del Error CuadrÃ¡tico Medio) y se comparan en tÃ©rminos de precisiÃ³n y tiempo de ejecuciÃ³n.

## ğŸ“Œ Datos Escalados vs. No Escalados
Inicialmente, los modelos fueron entrenados con datos sin escalar, obteniendo los siguientes resultados:

RegresiÃ³n Lineal: RECM superior a 3000.
Ãrbol de DecisiÃ³n y Bosque Aleatorio: RECM cercano a 2000.
LightGBM: Mejor desempeÃ±o con un RECM de ~1700.
Luego, se decidiÃ³ escalar los datos, lo que mejorÃ³ notablemente el desempeÃ±o de los modelos de RegresiÃ³n Lineal, Ãrbol de DecisiÃ³n y Bosque Aleatorio. Sin embargo, LightGBM tuvo un mejor rendimiento con los datos sin escalar.

## ğŸ“Œ TecnologÃ­as y Herramientas
Este proyecto utiliza las siguientes herramientas:

- ğŸ–¥ Jupyter Notebook (Todo el cÃ³digo se encuentra en estimacion_precios.ipynb).
- ğŸ Python 3.x
- ğŸ“Š Pandas y NumPy (ManipulaciÃ³n de datos).
- ğŸ¤– Scikit-learn (Modelos de Machine Learning).
- âš¡ LightGBM (Modelo basado en potenciaciÃ³n del gradiente).
- ğŸ“‰ Matplotlib y Seaborn (VisualizaciÃ³n de datos).

## ğŸ“‚ Contenido del Proyecto
- ğŸ“„ `notebooks/` â†’ Contiene el cÃ³digo en **Jupyter Notebook**.
- ğŸ“Š `data/` â†’ Conjunto de datos utilizado para entrenar los modelos.
- ğŸ“œ `README.md` â†’ Este archivo con la descripciÃ³n del proyecto.

## ğŸš€ CÃ³mo Usar el Proyecto
1ï¸âƒ£ Clonar el repositorio:
   ```bash
   git clone https://github.com/Scarleth6o6/prices_prediction.git
   ```
2ï¸âƒ£ Instalar las dependencias:
   ```bash
   pip install -r requirements.txt
   ```
3ï¸âƒ£ Ejecutar el notebook en Jupyter Notebook o Google Colab.
   ```bash
   jupyter notebook
   ```
4ï¸âƒ£ Abre el archivo estimacion_precios.ipynb y ejecuta las celdas.

ğŸ“Œ AnÃ¡lisis de Resultados
Los modelos fueron evaluados en funciÃ³n de RECM (RaÃ­z del Error CuadrÃ¡tico Medio) y tiempo de ejecuciÃ³n.

- ğŸ”¹ RegresiÃ³n Lineal: Modelo mÃ¡s rÃ¡pido, pero con una menor precisiÃ³n.
- ğŸ”¹ Ãrbol de DecisiÃ³n y Bosque Aleatorio: Buena precisiÃ³n, pero mayor tiempo de entrenamiento.
- ğŸ”¹ LightGBM: No mostrÃ³ mejoras significativas y su desempeÃ±o fue mejor sin escalar los datos.

## ğŸ“Œ ConclusiÃ³n
Este proyecto demuestra que, aunque modelos avanzados como LightGBM pueden ser potentes, los modelos mÃ¡s simples como RegresiÃ³n Lineal y Random Forest pueden ofrecer resultados competitivos dependiendo del balance entre precisiÃ³n y velocidad de entrenamiento.

Si se prioriza la velocidad, RegresiÃ³n Lineal es la mejor opciÃ³n.
Si se busca precisiÃ³n, Random Forest tiene mejor desempeÃ±o.

## ğŸ“Œ Mejoras Futuras
ğŸš€ Evaluar otros modelos como XGBoost o SVM.
ğŸš€ Realizar un anÃ¡lisis de importancia de caracterÃ­sticas.
ğŸš€ Implementar validaciÃ³n cruzada para mejorar la evaluaciÃ³n de los modelos.

## ğŸ“Œ Contribuciones
Si deseas contribuir a este proyecto:

- 1ï¸âƒ£ Haz un fork del repositorio.
- 2ï¸âƒ£ Crea una nueva rama (git checkout -b feature/nueva-caracteristica).
- 3ï¸âƒ£ Realiza tus cambios y haz commit (git commit -am "AÃ±adir nueva caracterÃ­stica").
- 4ï¸âƒ£ Haz push a la rama (git push origin feature/nueva-caracteristica).
- 5ï¸âƒ£ Abre un Pull Request.
- ğŸ“… **Ãšltima actualizaciÃ³n:** Marzo 2025
